{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport shutil\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport itertools\n\n\nfrom skimage.filters import gaussian\nfrom skimage.util import random_noise\nimport matplotlib.image as mpimg\n\nfrom sklearn.model_selection import train_test_split\n\n\n\nimport tensorflow\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.models import model_from_json\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import Conv2D\nfrom tensorflow.keras.layers import MaxPool2D,Dropout,MaxPooling2D\nfrom tensorflow.keras.layers import Flatten\nfrom tensorflow.keras.callbacks import EarlyStopping,ModelCheckpoint\n","metadata":{"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# accsess the data files and dir\ncancer_rays_dir     = os.listdir(\"../input/breast-histopathology-images/IDC_regular_ps50_idx5\") \nall_rays_dir        = \"all_rays_dir\"  # is this path we will put all the images\ncancer_rays_dir_str =\"../input/breast-histopathology-images/IDC_regular_ps50_idx5/\"","metadata":{"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"print(cancer_rays_dir)\nprint(len(cancer_rays_dir)) ","metadata":{"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"##### We can see 279 files for each patient named with their id, and each file contains x-ray images of its owner","metadata":{}},{"cell_type":"markdown","source":"### To facilitate the process of dealing with screening mammograms images, we will collect all the images in one place, while retaining ownership of each image and its class as well...","metadata":{}},{"cell_type":"code","source":"os.mkdir(all_rays_dir)\n","metadata":{"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"all_rays_dir_lst = os.listdir('./all_rays_dir') ","metadata":{"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"#Here we will move the images, but by adding a small part in their path, which indicates that they are negative or positive\nfor patient in cancer_rays_dir:   \n    path_0 = cancer_rays_dir_str + str(patient) + '/0'\n    path_1 = cancer_rays_dir_str + str(patient) + '/1'\n    file_list_0 = os.listdir(path_0)   \n    file_list_1 = os.listdir(path_1)\n    for fname in file_list_0:\n            src = os.path.join(path_0, fname)\n            dst = os.path.join(all_rays_dir, fname)\n            shutil.copyfile(src, dst)\n    for fname in file_list_1:\n        src = os.path.join(path_1, fname)\n        dst = os.path.join(all_rays_dir, fname)\n        shutil.copyfile(src, dst)","metadata":{"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"all_rays_dir_lst = os.listdir('./all_rays_dir') \nlen(all_rays_dir_lst)","metadata":{"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"from glob import glob\n","metadata":{"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"files = glob('/kaggle/input/breast-histopathology-images/*/*/*')","metadata":{"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"!pip install keras","metadata":{"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"from tensorflow import keras","metadata":{"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import load_img, img_to_array","metadata":{"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"#viewing the dataset\ndef show_img(files):\n    plt.figure(figsize= (10,10))\n    ind = np.random.randint(0, len(files), 25)\n    i=0\n    for loc in ind:\n        plt.subplot(5,5,i+1)\n        sample = load_img(files[loc], target_size=(150,150))\n        sample = img_to_array(sample)\n        plt.axis(\"off\")\n        plt.imshow(sample.astype(\"uint8\"))\n        i+=1\n        \n        \nshow_img(files)","metadata":{"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"##### Now we have 277,524 images, what a number!","metadata":{}},{"cell_type":"markdown","source":"### Then, it's time to put images in a data_frame for easy access:","metadata":{}},{"cell_type":"code","source":"data = pd.DataFrame(all_rays_dir_lst, columns=['image_id'])\ndata.head()\n","metadata":{"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"#Based on the addition that we added earlier in the path, we divide the data\ndef extract_target(x):\n    a = x.split('_')\n    b = a[4]\n    target = b[5] \n    return target\n\ndata['target'] = data['image_id'].apply(extract_target)\n\ndata.head(10)","metadata":{"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"def extract_patient_id(x):\n    # split into a list\n    a = x.split('_')\n    patient_id = a[0]\n    \n    return patient_id\ndata['patient_id'] = data['image_id'].apply(extract_patient_id)\ndata.head()","metadata":{"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"data['target'].value_counts()","metadata":{"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"#### It also seems that the number of healthy rays is greater than the number of infected rays, good news!","metadata":{}},{"cell_type":"markdown","source":"> # Exploratory Data Analysis","metadata":{}},{"cell_type":"markdown","source":"#### First of all, let's take a look at the nature of the mammograms...","metadata":{}},{"cell_type":"markdown","source":"## Healthy patches:\n","metadata":{}},{"cell_type":"code","source":"data.target = data.target.astype(np.int)\nfig, ax = plt.subplots(5,10,figsize=(20,10))\npos_selection = np.random.choice(data[data.target ==1].index, size=50, replace=False,)\nneg_selection = np.random.choice(data[data.target ==0].index, size=50, replace=False,)\nfor n in range(5):\n    for m in range(10):\n        idx = neg_selection[m + 10*n]\n        path =os.path.join(all_rays_dir,data.loc[idx, 'image_id'])\n        image = mpimg.imread(path)\n        ax[n,m].imshow(image)\n        ax[n,m].grid(False)\n\n\n","metadata":{"scrolled":true,"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"### Insights\n- Most of the mammograms are light pink, but there are some dark ones too","metadata":{}},{"cell_type":"markdown","source":"# Cancer patches:","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(5,10,figsize=(20,10))\nfor n in range(5):\n    for m in range(10):\n        idx = pos_selection[m + 10*n]\n        path =os.path.join(all_rays_dir,data.loc[idx, 'image_id'])\n        image = mpimg.imread(path)\n        ax[n,m].imshow(image)\n        ax[n,m].grid(False)\n","metadata":{"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"### Insights\n\n- Patches with cancer look more violet and crowded than healthy ones. \n- In fact, we could not determine the actual difference between the two types with the naked eye, but I think that the model is able to detect hidden patterns in these images that enable us to determine the state of each image.","metadata":{}},{"cell_type":"markdown","source":"### Let's ask some questions that will help us get to know more our data:\n- do all patients have the same number of mammograms?\n- what is the percentage of cancer (IDC) that each mammogram shows? \n- how many healthy and cancered mammograms are in the data?","metadata":{}},{"cell_type":"code","source":"cancer_perc = data.groupby(\"patient_id\").target.value_counts()/ data.groupby(\"patient_id\").target.size()\ncancer_perc = cancer_perc.unstack()\n\nfig, ax = plt.subplots(1,3,figsize=(20,5))\nsns.distplot(data.groupby(\"patient_id\").size(), ax=ax[0], color=\"Red\", kde=False, bins=30)\nax[0].set_xlabel(\"Number of patches\")\nax[0].set_ylabel(\"Frequency\");\n\nsns.distplot(cancer_perc.loc[:, 1]*100, ax=ax[1], color=\"Blue\", kde=False, bins=30)\n\nax[1].set_ylabel(\"Frequency\")\nax[1].set_xlabel(\"% of patches with IDC\");\nsns.countplot(data.target, palette=\"Set1\", ax=ax[2]);\nax[2].set_xlabel(\"no(0) versus yes(1)\")\n","metadata":{"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":"### Insights:\n- The number of image patches per patient varies a lot\n- Most of the photos have a percentage that is not large, but there are other photos that have a percentage of up to 80%\n- the smaller number of mammograms had cancer","metadata":{}},{"cell_type":"code","source":"def extract_coords(df):\n    coord = df.path.str.rsplit(\"_\", n=4, expand=True)\n    coord = coord.drop([0, 1, 4], axis=1)\n    coord = coord.rename({2: \"x\", 3: \"y\"}, axis=1)\n    coord.loc[:, \"x\"] = coord.loc[:,\"x\"].str.replace(\"x\", \"\", case=False).astype(np.int)\n    coord.loc[:, \"y\"] = coord.loc[:,\"y\"].str.replace(\"y\", \"\", case=False).astype(np.int)\n    df.loc[:, \"x\"] = coord.x.values\n    df.loc[:, \"y\"] = coord.y.values\n    return df\n\ndef get_cancer_dataframe(patient_id, cancer_id):\n    path = cancer_rays_dir_str + patient_id + \"/\" + cancer_id\n    files = os.listdir(path)\n    dataframe = pd.DataFrame(files, columns=[\"filename\"])\n    path_names = path + \"/\" + dataframe.filename.values\n    dataframe = dataframe.filename.str.rsplit(\"_\", n=4, expand=True)\n    dataframe.loc[:, \"target\"] = np.int(cancer_id)\n    dataframe.loc[:, \"path\"] = path_names\n    dataframe = dataframe.drop([0, 1, 4], axis=1)\n    dataframe = dataframe.rename({2: \"x\", 3: \"y\"}, axis=1)\n    dataframe.loc[:, \"x\"] = dataframe.loc[:,\"x\"].str.replace(\"x\", \"\", case=False).astype(np.int)\n    dataframe.loc[:, \"y\"] = dataframe.loc[:,\"y\"].str.replace(\"y\", \"\", case=False).astype(np.int)\n    return dataframe\ndef get_patient_dataframe(patient_id):\n    df_0 = get_cancer_dataframe(patient_id, \"0\")\n    df_1 = get_cancer_dataframe(patient_id, \"1\")\n    patient_df = df_0.append(df_1)\n    return patient_df","metadata":{"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"example = get_patient_dataframe(data.patient_id.values[0])\nexample.head()","metadata":{"scrolled":true,"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"markdown","source":"### Well let's take a closer look at the shape of the patches and their distribution in each mammogram using Binary objective visualization for each tissue slice:","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(5,3,figsize=(20, 27))\n\npatient_ids = data.patient_id.unique()\n\nfor n in range(5):\n    for m in range(3):\n        patient_id = patient_ids[m + 3*n]\n        example_df = get_patient_dataframe(patient_id)\n        \n        ax[n,m].scatter(example_df.x.values, example_df.y.values, c=example_df.target.values, cmap=\"RdYlBu\", s=20);\n        ax[n,m].set_title(\"patient \" + patient_id)\n        ax[n,m].set_xlabel(\"y coord\")\n        ax[n,m].set_ylabel(\"x coord\")","metadata":{"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"markdown","source":"### Insights:\n\n- We see a large variation in the concentration of cells\n- Sometimes we don't have the full tissue information. It seems that tissue patches have been discarded or lost during preparation.","metadata":{}},{"cell_type":"markdown","source":"> # Processing and selection\nit's time to work on our data..","metadata":{}},{"cell_type":"markdown","source":"# Image Processing ","metadata":{}},{"cell_type":"markdown","source":"-  Apply some processing properties","metadata":{}},{"cell_type":"code","source":"data.target = data.target.astype(np.int)\nrandom_image_path = np.random.choice(data[data.target ==0].index, size=1, replace=False,)\npath =os.path.join(all_rays_dir,data.loc[random_image_path[0], 'image_id'])\nimage = mpimg.imread(path)\nplt.imshow(image)","metadata":{"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"gaussian_image = gaussian(image)\nplt.imshow(gaussian_image)","metadata":{"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"noise_image = random_noise(image)\nplt.imshow(noise_image)","metadata":{"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"noise_gaussian_image = random_noise(gaussian_image)\nplt.imshow(noise_gaussian_image)","metadata":{"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"markdown","source":"-  Processing using (random_noise) function","metadata":{}},{"cell_type":"code","source":"os.mkdir('image_processing') #We create a new file to process the data in\nos.mkdir('image_processing/noise_images')","metadata":{"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"#Here we take the image from the normal images folder, process it, and then save it in the new file\nfor normal_image in all_rays_dir_lst :\n    path        = all_rays_dir+'/'+ normal_image\n    img         = mpimg.imread( path ,0)\n    noise_image = random_noise(img)\n    fname       = normal_image\n    new_path    = os.path.join('image_processing/noise_images',fname)\n    mpimg.imsave(new_path, noise_image)\n    ","metadata":{"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"os.mkdir( 'image_processing/processd_data_train')\nos.mkdir( 'image_processing/processd_data_test')\nos.mkdir( 'image_processing/processd_data_train/zeros')\nos.mkdir( 'image_processing/processd_data_train/ones')\nos.mkdir( 'image_processing/processd_data_test/zeros')\nos.mkdir( 'image_processing/processd_data_test/ones')\n","metadata":{"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"\nprocessd_lst = os.listdir('image_processing/noise_images')\nprocessd_lst_str = 'image_processing/noise_images'\nprocessd_data = pd.DataFrame(processd_lst, columns=['image_id'])\nprocessd_data.head()","metadata":{"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"def extract_target(x):\n    a = x.split('_')\n    b = a[4]\n    target = b[5] \n    return target\n\nprocessd_data['target'] = processd_data['image_id'].apply(extract_target)\n\nprocessd_data.head(10)","metadata":{"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"processd_data['target'].value_counts()","metadata":{"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"y = processd_data['target']\nprocessd_train, processd_test = train_test_split(processd_data, test_size=0.10, random_state=101, stratify=y)\nprocessd_test_pls =processd_test.image_id\nprocessd_train_pls =processd_train.image_id","metadata":{"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"processd_data.set_index('image_id', inplace=True)\nfor image in processd_test_pls:\n    fname = image\n    target = processd_data.loc[image,'target']\n    if target == '0':\n        label = 'zeros'\n    if target == '1':\n        label = 'ones'\n    src = os.path.join(processd_lst_str, fname)\n    dst = os.path.join(\"image_processing/processd_data_test\", label, fname)\n    shutil.copyfile(src, dst)\n","metadata":{"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"for image in processd_train_pls:\n    fname  = image\n    target = processd_data.loc[image,'target']\n    \n    if target == '0':\n        label = 'zeros'\n    if target == '1':\n        label = 'ones'\n    src = os.path.join(processd_lst_str, fname)\n    dst = os.path.join('image_processing/processd_data_train', label, fname)\n    shutil.copyfile(src, dst)","metadata":{"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"print(len(os.listdir('image_processing/processd_data_train/zeros')))\nprint(len(os.listdir('image_processing/processd_data_train/ones')))\nprint(len(os.listdir('image_processing/processd_data_test/zeros')))\nprint(len(os.listdir('image_processing/processd_data_test/ones')))","metadata":{"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"markdown","source":"# Processing  and Normal test","metadata":{}},{"cell_type":"markdown","source":"-  the images we processed and the noraml are tested on the same model to see which the best in the accuracy","metadata":{}},{"cell_type":"markdown","source":"-  A small sample is taken for testing (20,000) images","metadata":{}},{"cell_type":"markdown","source":"### First: the processed images","metadata":{}},{"cell_type":"code","source":"processd_lst = os.listdir('image_processing/noise_images')\nprocessd_lst_str = 'image_processing/noise_images'\nprocessd_data = pd.DataFrame(processd_lst, columns=['image_id'])\ndef extract_target(x):\n    a = x.split('_')\n    b = a[4]\n    target = b[5] \n    return target\n\nprocessd_data['target'] = processd_data['image_id'].apply(extract_target)\n\nprocessd_data.head(10)","metadata":{"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"os.mkdir( 'image_processing/model_tst')\nos.mkdir( 'image_processing/model_tst/trainig')\nos.mkdir( 'image_processing/model_tst/testing')          \nos.mkdir( 'image_processing/model_tst/trainig/zeros')\nos.mkdir( 'image_processing/model_tst/trainig/ones')\nos.mkdir( 'image_processing/model_tst/testing/zeros')\nos.mkdir( 'image_processing/model_tst/testing/ones')","metadata":{"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"df_0 = processd_data[processd_data['target'] == '0'].sample(10000, random_state=101)\ndf_1 = processd_data[processd_data['target'] == '1'].sample(10000, random_state=101)\ntest_data =pd.DataFrame(data)\ntest_data = pd.concat([df_0, df_1], axis=0).reset_index(drop=True)\ntest_y = test_data['target']\ntest_data_train, test_data_test = train_test_split(test_data, test_size=0.10, random_state=101, stratify=test_y)\nsts_train = test_data_train.image_id\ntst_test  = test_data_test.image_id\ntest_data.set_index('image_id', inplace=True)\nfor image in sts_train:\n    fname  = image\n    target = test_data.loc[image,'target']\n    \n    if target == '0':\n        label = 'zeros'\n    if target == '1':\n        label = 'ones'\n    src = os.path.join(all_rays_dir, fname)\n    dst = os.path.join('image_processing/model_tst/trainig', label, fname)\n    shutil.copyfile(src, dst)\nfor image in tst_test:\n    fname  = image\n    target = test_data.loc[image,'target']\n    \n    if target == '0':\n        label = 'zeros'\n    if target == '1':\n        label = 'ones'\n    src = os.path.join(all_rays_dir, fname)\n    dst = os.path.join('image_processing/model_tst/testing', label, fname)\n    shutil.copyfile(src, dst)    \n","metadata":{"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"processd_data.target = processd_data.target.astype(np.int)\nfig, ax = plt.subplots(5,4,figsize=(30,20))\npos_selection = np.random.choice(processd_data[processd_data.target==1].index.values, size=20, replace=False)\nneg_selection = np.random.choice(processd_data[processd_data.target==0].index.values, size=20, replace=False)\nfor n in range(5):\n    for m in range(4):\n        idx = pos_selection[m + 4*n]\n        path =os.path.join(processd_lst_str,processd_data.loc[idx, 'image_id'])\n        image = mpimg.imread(path)\n        ax[n,m].imshow(image)\n        ax[n,m].grid(False)","metadata":{"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"markdown","source":"- Here we show pictures of some of the processed carcinogenic images","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(5,4,figsize=(30,20))\nfor n in range(5):\n    for m in range(4):\n        idx = neg_selection[m + 4*n]\n        path =os.path.join(processd_lst_str,processd_data.loc[idx, 'image_id'])\n        image = mpimg.imread(path)\n        ax[n,m].imshow(image)\n        ax[n,m].grid(False)","metadata":{"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"markdown","source":"- Here we show pictures of some of the normal images that have been processed","metadata":{}},{"cell_type":"code","source":"data_processd_test_generation = ImageDataGenerator(rescale=1.0/255)\ntrain_generation_processd = data_processd_test_generation.flow_from_directory(\"image_processing/model_tst/trainig\", target_size=(50,50), batch_size=10,class_mode='categorical')\ntest_generation_processd = data_processd_test_generation.flow_from_directory(\"image_processing/model_tst/testing\",target_size=(50,50),batch_size=10,class_mode='categorical')","metadata":{"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"my_model_im_processd =Sequential()\nmy_model_im_processd.add(Conv2D(filters=32,kernel_size=(4,4),input_shape=(50,50,3),activation='relu'))\nmy_model_im_processd.add(MaxPool2D(pool_size=(2,2)))\n\n\nmy_model_im_processd.add(Flatten())\n\nmy_model_im_processd.add(Dense(128,activation='relu'))\n\nmy_model_im_processd.add(Dense(2,activation='softmax'))\n\nmy_model_im_processd.compile(loss = 'categorical_crossentropy', optimizer ='adam', metrics= ['accuracy'])","metadata":{"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"early_stop = EarlyStopping(monitor='val_loss',patience=2)\nmy_model_im_processd.fit_generator(train_generation_processd,validation_data=test_generation_processd,epochs=60, verbose=1,callbacks=early_stop)","metadata":{"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"markdown","source":"### Second: the normal images","metadata":{}},{"cell_type":"code","source":"os.mkdir( 'image_processing/normal')\nos.mkdir( 'image_processing/normal/model_tst') \nos.mkdir( 'image_processing/normal/model_tst/trainig')\nos.mkdir( 'image_processing/normal/model_tst/testing')\nos.mkdir( 'image_processing/normal/model_tst/trainig/zeros')\nos.mkdir( 'image_processing/normal/model_tst/trainig/ones')\nos.mkdir( 'image_processing/normal/model_tst/testing/zeros')\nos.mkdir( 'image_processing/normal/model_tst/testing/ones')","metadata":{"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"data = pd.DataFrame(all_rays_dir_lst, columns=['image_id'])\ndata['target'] = data['image_id'].apply(extract_target)\ndf_0 = data[data['target'] == '0'].sample(10000, random_state=101)\ndf_1 = data[data['target'] == '1'].sample(10000, random_state=101)\ntest_data =pd.DataFrame(data)\ntest_data = pd.concat([df_0, df_1], axis=0).reset_index(drop=True)\ntest_y = test_data['target']\ntest_data_train, test_data_test = train_test_split(test_data, test_size=0.10, random_state=101, stratify=test_y)\nsts_train = test_data_train.image_id\ntst_test  = test_data_test.image_id\ntest_data.set_index('image_id', inplace=True)\nfor image in sts_train:\n    fname  = image\n    target = test_data.loc[image,'target']\n    \n    if target == '0':\n        label = 'zeros'\n    if target == '1':\n        label = 'ones'\n    src = os.path.join(all_rays_dir, fname)\n    dst = os.path.join('image_processing/normal/model_tst/trainig', label, fname)\n    shutil.copyfile(src, dst)\nfor image in tst_test:\n    fname  = image\n    target = test_data.loc[image,'target']\n    \n    if target == '0':\n        label = 'zeros'\n    if target == '1':\n        label = 'ones'\n    src = os.path.join(all_rays_dir, fname)\n    dst = os.path.join('image_processing/normal/model_tst/testing', label, fname)\n    shutil.copyfile(src, dst)    \n","metadata":{"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"data_normal_test_generation = ImageDataGenerator(rescale=1.0/255)\ntrain_generation_normal = data_normal_test_generation.flow_from_directory(\"image_processing/normal/model_tst/trainig\", target_size=(50,50), batch_size=10,class_mode='categorical')\ntest_generation_normal = data_normal_test_generation.flow_from_directory(\"image_processing/normal/model_tst/testing\",target_size=(50,50),batch_size=10,class_mode='categorical')","metadata":{"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"my_model_im_norm =Sequential()\nmy_model_im_norm.add(Conv2D(filters=32,kernel_size=(4,4),input_shape=(50,50,3),activation='relu'))\nmy_model_im_norm.add(MaxPool2D(pool_size=(2,2)))\n\n\nmy_model_im_norm.add(Flatten())\n\nmy_model_im_norm.add(Dense(128,activation='relu'))\nmy_model_im_norm.add(Dense(2,activation='softmax'))\n\nmy_model_im_norm.compile(loss = 'categorical_crossentropy', optimizer ='adam', metrics= ['accuracy'])","metadata":{"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"early_stop = EarlyStopping(monitor='val_loss',patience=2)\nmy_model_im_processd.fit_generator(train_generation_normal,validation_data=test_generation_normal,epochs=60, verbose=1,callbacks=early_stop)","metadata":{"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"markdown","source":"## conclusion : Normal images are the best in modeling ","metadata":{}},{"cell_type":"markdown","source":"> # Modeling","metadata":{}},{"cell_type":"markdown","source":"# Data Spliting & Generation","metadata":{}},{"cell_type":"code","source":"data = pd.DataFrame(all_rays_dir_lst, columns=['image_id'])\ndef extract_target(x):\n    a = x.split('_')\n    b = a[4]\n    target = b[5] \n    return target\n\ndata['target'] = data['image_id'].apply(extract_target)\n\ndata.head()","metadata":{"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"y = data['target']\ndata_train, data_test = train_test_split(data, test_size=0.10, random_state=101, stratify=y)","metadata":{"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"print(data_train.shape)\nprint(data_test.shape)","metadata":{"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"os.mkdir( 'train_dir')\nos.mkdir('test_dir')","metadata":{"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"code","source":"os.mkdir( 'train_dir/zeros')\nos.mkdir( 'train_dir/ones')\n\nos.mkdir( 'test_dir/zeros')\nos.mkdir( 'test_dir/ones')\n","metadata":{"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"train = data_train.image_id\ntest  = data_test.image_id","metadata":{"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"data.set_index('image_id', inplace=True)\nfor image in train:\n    fname  = image\n    target = data.loc[image,'target']\n    \n    if target == '0':\n        label = 'zeros'\n    if target == '1':\n        label = 'ones'\n    src = os.path.join(all_rays_dir, fname)\n    dst = os.path.join('train_dir', label, fname)\n    shutil.copyfile(src, dst)","metadata":{"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"code","source":"for image in test:\n    fname = image\n    target = data.loc[image,'target']\n    if target == '0':\n        label = 'zeros'\n    if target == '1':\n        label = 'ones'\n    src = os.path.join(all_rays_dir, fname)\n    dst = os.path.join(\"test_dir\", label, fname)\n    shutil.copyfile(src, dst)\n","metadata":{"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"code","source":"print('non-IDC train      =',len(os.listdir('train_dir/zeros')))\nprint('IDC train          =',len(os.listdir('train_dir/ones')))\nprint('non-IDC validation =',len(os.listdir('test_dir/zeros')))\nprint('IDC validation     =',len(os.listdir('test_dir/ones')))","metadata":{"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"data_generation = ImageDataGenerator(rescale=1.0/255)","metadata":{"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"train_generation = data_generation.flow_from_directory(\n                                        \"train_dir\",\n                                        target_size=(25,25),\n                                        batch_size=10,\n                                        class_mode='categorical')\ntest_generation = data_generation.flow_from_directory(\n                                        \"test_dir\",\n                                        target_size=(25,25),\n                                        batch_size=10,\n                                        class_mode='categorical')\n\n","metadata":{"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"markdown","source":"># Model design","metadata":{}},{"cell_type":"code","source":"my_model =Sequential()\nmy_model.add(Conv2D(filters=32,kernel_size=(4,4),input_shape=(25,25,3),activation='relu'))\nmy_model.add(Conv2D(filters=32,kernel_size=(4,4),input_shape=(25,25,3),activation='relu'))\nmy_model.add(MaxPool2D(pool_size=(2,2)))\nmy_model.add(Dropout(.3))\n\nmy_model.add(Flatten())\n\nmy_model.add(Dense(256,activation='relu'))\n\nmy_model.add(Dense(2,activation='softmax'))\n\nmy_model.compile(loss = 'categorical_crossentropy', optimizer ='adam', metrics= ['accuracy'])","metadata":{"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"code","source":"my_model.summary()","metadata":{"trusted":true},"execution_count":83,"outputs":[]},{"cell_type":"code","source":"my_model.fit_generator(train_generation,validation_data=test_generation,epochs=60, verbose=1,callbacks=early_stop)","metadata":{"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"markdown","source":"># Outputs and Outcomes","metadata":{}},{"cell_type":"code","source":"losse = pd.DataFrame(my_model.history.history)\nlosse.head()","metadata":{"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"code","source":"losse[['accuracy','val_accuracy']].plot()","metadata":{"trusted":true},"execution_count":86,"outputs":[]},{"cell_type":"code","source":"losse[['loss','val_loss']].plot()\n","metadata":{"trusted":true},"execution_count":87,"outputs":[]},{"cell_type":"code","source":"val_loss, val_acc = \\\nmy_model.evaluate_generator(test_generation)\n\nprint('val_loss:', val_loss)\nprint('val_acc:', val_acc)","metadata":{"trusted":true},"execution_count":92,"outputs":[]}]}